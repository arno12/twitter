{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import tweepy\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from settings import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glimpse(df, maxvals=10, maxlen=110):\n",
    "    print('Shape: ', df.shape)\n",
    "    \n",
    "    def pad(y):\n",
    "        max_len = max([len(x) for x in y])\n",
    "        return [x.ljust(max_len) for x in y]\n",
    "    \n",
    "    # Column Name\n",
    "    toprnt = pad(df.columns.tolist())\n",
    "    \n",
    "    # Column Type\n",
    "    toprnt = pad([toprnt[i] + ' ' + str(df.iloc[:,i].dtype) for i in range(df.shape[1])])\n",
    "    \n",
    "    # Num NAs\n",
    "    num_nas = [df.iloc[:,i].isnull().sum() for i in range(df.shape[1])]\n",
    "    num_nas_ratio = [int(round(x*100/df.shape[0])) for x in num_nas]\n",
    "    num_nas_str = [str(x) + ' (' + str(y) + '%)' for x,y in zip(num_nas, num_nas_ratio)]\n",
    "    max_len = max([len(x) for x in num_nas_str])\n",
    "    num_nas_str = [x.rjust(max_len) for x in num_nas_str]\n",
    "    toprnt = [x + ' ' + y + ' NAs' for x,y in zip(toprnt, num_nas_str)]\n",
    "    \n",
    "    # Separator\n",
    "    toprnt = [x + ' : ' for x in toprnt]\n",
    "    \n",
    "    # Values\n",
    "    toprnt = [toprnt[i] + ', '.join([str(y) for y in df.iloc[:min([maxvals,df.shape[0]]), i]]) for i in range(df.shape[1])]\n",
    "    \n",
    "    # Trim to maxlen\n",
    "    toprnt = [x[:min(maxlen, len(x))] for x in toprnt]\n",
    "    \n",
    "    for x in toprnt:\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/c/Users/arnop/Documents/self_dev/twitter_api_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    companies = [\"blendle\", \"cafeyn\", \"milibris\", \"readly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 30 days ago - which is the maximum time Twitter allows you to go in the past.\n",
    "    date_since = datetime.now() - timedelta(days=30)\n",
    "    date_since = date_since.strftime(\"%Y-%m-%d\")\n",
    "    date_now = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "    # create results folder if it doesn't exist yet\n",
    "    Path(\"./results\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load previous data if it exists\n",
    "    last_31days_results_path: Path = Path(\"./results/twitter_searches_last_31_days.tsv\")\n",
    "    new_results_path = Path(\"./results/twitter_searches_incremental.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_31days_results_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1948, 10)\n",
      "id                float64    0 (0%) NAs : 1.4053299059534766e+18, 1.405288843897557e+18, 1.4052621984322191e+1\n",
      "iso_language_code object     0 (0%) NAs : nl, de, de, de, nl, nl, fr, fr, fr, en\n",
      "created_at        object     0 (0%) NAs : 2021-06-17 01:02:14+00:00, 2021-06-16 22:19:04+00:00, 2021-06-16 20:\n",
      "screen_name       object     0 (0%) NAs : nieuwsselectie, sebasobo, niggi, guebartsch, BlendleNL, BlendleNL, M\n",
      "text              object     0 (0%) NAs : Onbeperkt tijdschriften en het nieuws van alle k(r)anten. Probeer gr\n",
      "location          object  398 (20%) NAs : nan, Wiesbaden, Deutschland, Berlin, Berlin, Utrecht, Utrecht, Toulo\n",
      "favorite_count    int64      0 (0%) NAs : 0, 0, 14, 2, 0, 0, 0, 0, 3, 1\n",
      "retweet_count     int64      0 (0%) NAs : 0, 0, 3, 0, 0, 0, 0, 0, 0, 0\n",
      "queried_at        object     0 (0%) NAs : 2021-06-17 06:00:07+00:00, 2021-06-17 06:00:07+00:00, 2021-06-17 06:\n",
      "company           object     0 (0%) NAs : blendle, blendle, blendle, blendle, blendle, blendle, cafeyn, cafeyn\n"
     ]
    }
   ],
   "source": [
    "last_31days_results = (\n",
    "    pd.read_csv(last_31days_results_path, sep=\"\\t\", parse_dates=['queried_at','created_at'])\n",
    "    if last_31days_results_path.is_file()\n",
    "    else pd.DataFrame(columns=[\"id\"])\n",
    ")\n",
    "glimpse(last_31days_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-06-16 15:08:52.218862')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('today') - pd.to_timedelta(\"31day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "utc=pytz.UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-06-16 15:45:42.137994+0000', tz='UTC')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime((datetime.now().replace(tzinfo=pytz.UTC) - pd.to_timedelta(\"31day\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1948, 10)\n",
      "id                float64    0 (0%) NAs : 1.4053299059534766e+18, 1.405288843897557e+18, 1.4052621984322191e+1\n",
      "iso_language_code object     0 (0%) NAs : nl, de, de, de, nl, nl, fr, fr, fr, en\n",
      "created_at        object     0 (0%) NAs : 2021-06-17 01:02:14+00:00, 2021-06-16 22:19:04+00:00, 2021-06-16 20:\n",
      "screen_name       object     0 (0%) NAs : nieuwsselectie, sebasobo, niggi, guebartsch, BlendleNL, BlendleNL, M\n",
      "text              object     0 (0%) NAs : Onbeperkt tijdschriften en het nieuws van alle k(r)anten. Probeer gr\n",
      "location          object  398 (20%) NAs : nan, Wiesbaden, Deutschland, Berlin, Berlin, Utrecht, Utrecht, Toulo\n",
      "favorite_count    int64      0 (0%) NAs : 0, 0, 14, 2, 0, 0, 0, 0, 3, 1\n",
      "retweet_count     int64      0 (0%) NAs : 0, 0, 3, 0, 0, 0, 0, 0, 0, 0\n",
      "queried_at        object     0 (0%) NAs : 2021-06-17 06:00:07+00:00, 2021-06-17 06:00:07+00:00, 2021-06-17 06:\n",
      "company           object     0 (0%) NAs : blendle, blendle, blendle, blendle, blendle, blendle, cafeyn, cafeyn\n"
     ]
    }
   ],
   "source": [
    "last_31days_results = (\n",
    "    pd.read_csv(last_31days_results_path, sep=\"\\t\", parse_dates=[\"created_at\"])\n",
    "    if last_31days_results_path.is_file()\n",
    "    else pd.DataFrame(columns=[\"id\"])\n",
    ")\n",
    "\n",
    "glimpse(last_31days_results)\n",
    "\n",
    "#last_31days_results = last_31days_results[last_31days_results['created_at'] > (last_31days_results['created_at'] > pd.to_datetime(datetime.now().replace(tzinfo=pytz.UTC) - pd.to_timedelta(\"31day\")))]\n",
    "\n",
    "#print(f\"the length of it is {last_31days_results.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't compare offset-naive and offset-aware datetimes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-525d79f76aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlast_31days_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11206\u001b[0m         )\n\u001b[1;32m  11207\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11210\u001b[0m         \u001b[0;31m# pandas\\core\\generic.py:11009: error: Cannot assign to a method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10710\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10711\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  10712\u001b[0m             \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10713\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10705\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10706\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  10707\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10708\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                 )\n\u001b[1;32m   4151\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mreduction\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/twitter/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     42\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: can't compare offset-naive and offset-aware datetimes"
     ]
    }
   ],
   "source": [
    "last_31days_results[\"created_at\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create logs folder if it doesn't exist yet\n",
    "    Path(\"./logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logs_path = Path(\"./logs/logs.csv\")\n",
    "\n",
    "    logs = (\n",
    "        pd.read_csv(logs_path)\n",
    "        if logs_path.is_file()\n",
    "        else pd.DataFrame(columns=[\"imported_at\", \"company\", \"total_rows\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # initialize empty df for last 31 days - so we can add each company tweet id's to it in the loop\n",
    "    col_names = [\n",
    "        \"id\",\n",
    "        \"iso_language_code\",\n",
    "        \"created_at\",\n",
    "        \"screen_name\",\n",
    "        \"text\",\n",
    "        \"location\",\n",
    "        \"favorite_count\",\n",
    "        \"retweet_count\",\n",
    "        \"queried_at\",\n",
    "        \"company\",\n",
    "    ]\n",
    "\n",
    "    last_31days_container = pd.DataFrame(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with blendle...\n",
      "original size of new df for blendle: 100\n",
      "existing id's of blendle in last 31 days: 99\n",
      "Done! Wrote a total of 1 new row(s) for blendle\n",
      "The new length of the last 31 days file is 376\n",
      "Starting with cafeyn...\n",
      "original size of new df for cafeyn: 110\n",
      "existing id's of cafeyn in last 31 days: 107\n",
      "Done! Wrote a total of 3 new row(s) for cafeyn\n",
      "The new length of the last 31 days file is 379\n",
      "Starting with milibris...\n",
      "original size of new df for milibris: 5\n",
      "existing id's of milibris in last 31 days: 5\n",
      "Done! Wrote a total of 0 new row(s) for milibris\n",
      "The new length of the last 31 days file is 379\n",
      "Starting with readly...\n",
      "original size of new df for readly: 164\n",
      "existing id's of readly in last 31 days: 164\n",
      "Done! Wrote a total of 0 new row(s) for readly\n",
      "The new length of the last 31 days file is 379\n"
     ]
    }
   ],
   "source": [
    "    for company in companies:\n",
    "        print(\"Starting with {}...\".format(company))\n",
    "        query = company + \" -filter:retweets\"\n",
    "\n",
    "        tweets = tweepy.Cursor(\n",
    "            api.search,\n",
    "            q=query,\n",
    "            # geocode=\"51.969685,4.051642,1000km\",\n",
    "            count=100,\n",
    "            result_type=\"recent\",\n",
    "            include_entities=True,\n",
    "            since=date_since,\n",
    "            tweet_mode=\"extended\",\n",
    "        ).items(1000)\n",
    "        locs = [\n",
    "            [\n",
    "                tweet.id,\n",
    "                tweet.metadata[\"iso_language_code\"],\n",
    "                tweet.created_at,\n",
    "                tweet.user.screen_name,\n",
    "                tweet.full_text,\n",
    "                tweet.user.location,\n",
    "                tweet.favorite_count,\n",
    "                tweet.retweet_count,\n",
    "                datetime.now(),\n",
    "                company,\n",
    "            ]\n",
    "            for tweet in tweets\n",
    "        ]\n",
    "\n",
    "        # latest data\n",
    "        df = pd.DataFrame(\n",
    "            data=locs,\n",
    "            columns=col_names,\n",
    "        )\n",
    "        print(f\"original size of new df for {company}: {len(df)}\")\n",
    "\n",
    "        # Identify what values are in last_results and not in df\n",
    "        existing_ids = list(set(last_31days_results.id).intersection(df.id))\n",
    "        print(f\"existing id's of {company} in last 31 days: {len(existing_ids)}\")\n",
    "        # Exclude rows that contain id's that we already have from a previous iteration\n",
    "        new_ids = df[~df.id.isin(existing_ids)]\n",
    "\n",
    "        # Append new rows to existing result set\n",
    "        new_ids.to_csv(\n",
    "            new_results_path,\n",
    "            mode=\"a\",\n",
    "            header=not Path(new_results_path).is_file(),\n",
    "            index=False,\n",
    "            sep=\"\\t\",\n",
    "        )\n",
    "\n",
    "        # Print logs\n",
    "        print(f\"Done! Wrote a total of {len(new_ids)} new row(s) for {company}\")\n",
    "\n",
    "        # Upload to s3\n",
    "        upload_file(\n",
    "            \"./results/twitter_searches_incremental.tsv\",\n",
    "            \"arno12-tweets\",\n",
    "            \"all-tweets/twitter_searches_incremental.tsv\",\n",
    "        )\n",
    "\n",
    "        last_31days_results = pd.concat([last_31days_results, new_ids])\n",
    "        print(\n",
    "            f\"The new length of the last 31 days file is {len(last_31days_results)}\"\n",
    "        )\n",
    "\n",
    "        # Generate logs\n",
    "        logs = pd.DataFrame(\n",
    "            data=[[datetime.now().timestamp(), company, len(df.index)]],\n",
    "            columns=[\"imported_at\", \"company\", \"total_rows\"],\n",
    "        )\n",
    "\n",
    "        logs.to_csv(\n",
    "            logs_path, mode=\"a\", header=not Path(logs_path).is_file(), index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_31days_container.to_csv(\n",
    "    './results/twitter_searches_last_31_days.tsv',\n",
    "    index=False,\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
